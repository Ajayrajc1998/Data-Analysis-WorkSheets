{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f63abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0fa1a97",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604a5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2000e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b8f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf0136d9",
   "metadata": {},
   "source": [
    "### Weight Intialization Techniques\n",
    "#### He Intialization$(np.random.rand(size_l,size_l-1)\\times \\sqrt{\\frac{2}{size_{l}-1}}$\n",
    "#### Xavier Intialization $(np.random.rand(size_l,size-)\\times \\sqrt{\\frac{1}{size_{l}-1}}$\n",
    "#### Xavierr Inti \n",
    "#### size-l is size of the lth layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6e2b2",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "### **********************\n",
    "### Sigmoid function\n",
    "### ------------------\n",
    "#### $$\\frac{1}{1+e^{-z}}$$,range 0-1,derivative range 0-0.25\n",
    "### tanh(threshold activation) function\n",
    "### ------------------------------------\n",
    "#### $$\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$, range -1 to 1, derivative range 0-1\n",
    "### ReLU function(used in hidden layer, solves vanishing gradient problem since its derivative is 1 or 0)\n",
    "### --------------------------------\n",
    "#### $$ReLU=max(0,x)$$, derivative is always 1 or 0\n",
    "### Leaky Relu\n",
    "### ------------\n",
    "#### $$f(x)=max(0.01x,x)$$,inorder to handle dead activation(dying ReLu point)\n",
    "### ELU\n",
    "### -----\n",
    "#### (using when vanishing gradient while implementing Leaky ReLu)\n",
    "#### $$f(x)=\\begin{cases}x, & \\text{if x>0}\\\\ \\alpha(e^{x}-1), & \\text{otherwise} \\end{cases}$$ \n",
    "### PReLU(Parametric ReLU)\n",
    "### -----------------------------------\n",
    "#### $$f(x)=\\begin{cases}x, & \\text{if x>0}\\\\ \\alpha.x, & \\text{otherwise}\\end{cases}$$\n",
    "#### where alpha is learning parameter\n",
    "### Softmax\n",
    "### -----------\n",
    "#### $$S(x_j)=\\frac{e^{x_j}}{\\sum\\limits_{k=1}^{K}e^{x_k}},j=1,2,...K$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac37966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a67de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_value=np.array([[0,0],[0,1],[1,1],[1,0]])\n",
    "input_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afac4a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e84ba1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_value=np.array([0,1,1,0]).reshape(4,1)\n",
    "output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3a1fc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a47934a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1],\n",
       "       [0.2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=np.array([[0.1],[0.2]])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d52aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb67e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f0d9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der(x):\n",
    "    return sigmoid_func(x)*(1-sigmoid_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "797786d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57444252],\n",
       "       [0.62245933],\n",
       "       [0.64565631],\n",
       "       [0.59868766]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_func(np.dot(input_arr,weights)+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48d1f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41953547]\n",
      " [ 8.98887811]]\n",
      "[-4.19706344]\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(10000):\n",
    "    input_arr=input_value\n",
    "    weighted_sum=np.dot(input_arr,weights)+bias\n",
    "    first_output=sigmoid_func(weighted_sum)\n",
    "    #error term\n",
    "    error=first_output-output_value\n",
    "    total_error=np.square(np.subtract(first_output,output_value)).mean()\n",
    "    #optmization\n",
    "    first_der=error\n",
    "    second_der=der(first_output)\n",
    "    derivative=first_der*second_der\n",
    "    t_input=input_value.T\n",
    "    final_derivative=np.dot(t_input,derivative)\n",
    "    weights=weights-0.05*final_derivative\n",
    "    for i in derivative:\n",
    "        bias=bias-0.05 * i\n",
    "print(weights)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "622fb831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01481684])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=np.array([0,0])\n",
    "result=np.dot(pred,weights)+bias\n",
    "res=sigmoid_func(result)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89843571",
   "metadata": {},
   "source": [
    "# usin Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28543ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f11567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI   \n",
       "0            6      148             72             35        0  33.6  \\\n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4fdd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Outcome', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=df['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe15b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Outcome',axis=1)\n",
    "y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37ac0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbde9f5",
   "metadata": {},
   "source": [
    "# Training neural model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdf951",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23182421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c663a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel=Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim=8,activation='relu'))\n",
    "kerasmodel.add(Dense(8,activation='relu'))\n",
    "kerasmodel.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d37bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "948f19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 1s 1ms/step - loss: 18.9167 - accuracy: 0.4691\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.5388 - accuracy: 0.5879\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.5954 - accuracy: 0.6254\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.3424 - accuracy: 0.6075\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.3772 - accuracy: 0.5700\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 903us/step - loss: 1.1349 - accuracy: 0.6075\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 1.0233 - accuracy: 0.5831\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 897us/step - loss: 0.9559 - accuracy: 0.6010\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.9208 - accuracy: 0.6059\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 901us/step - loss: 0.8783 - accuracy: 0.6091\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 924us/step - loss: 0.8523 - accuracy: 0.6303\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.8524 - accuracy: 0.6221\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 842us/step - loss: 0.8242 - accuracy: 0.6336\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.8036 - accuracy: 0.6254\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.8039 - accuracy: 0.6270\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.7742 - accuracy: 0.6384\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.7589 - accuracy: 0.6221\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.7727 - accuracy: 0.6173\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 908us/step - loss: 0.7241 - accuracy: 0.6319\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.7328 - accuracy: 0.6336\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 872us/step - loss: 0.7053 - accuracy: 0.6450\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.6515\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 948us/step - loss: 0.6842 - accuracy: 0.6287\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.6547\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 924us/step - loss: 0.6664 - accuracy: 0.6645\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 965us/step - loss: 0.6728 - accuracy: 0.6694\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.6524 - accuracy: 0.6629\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.6532 - accuracy: 0.6808\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.6386 - accuracy: 0.6726\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 805us/step - loss: 0.6419 - accuracy: 0.6743\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.6250 - accuracy: 0.6954\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.6288 - accuracy: 0.6824\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 820us/step - loss: 0.6232 - accuracy: 0.6840\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 860us/step - loss: 0.6475 - accuracy: 0.6694\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 807us/step - loss: 0.6301 - accuracy: 0.6645\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.6284 - accuracy: 0.6759\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.6067 - accuracy: 0.6922\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.6089 - accuracy: 0.6971\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.6027 - accuracy: 0.6857\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 925us/step - loss: 0.5994 - accuracy: 0.7117\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5996 - accuracy: 0.6906\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 861us/step - loss: 0.6071 - accuracy: 0.6792\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5941 - accuracy: 0.6938\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5938 - accuracy: 0.6987\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.6284 - accuracy: 0.6873\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5875 - accuracy: 0.6906\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 786us/step - loss: 0.5793 - accuracy: 0.7036\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 891us/step - loss: 0.5964 - accuracy: 0.6971\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 923us/step - loss: 0.5781 - accuracy: 0.6971\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 867us/step - loss: 0.5914 - accuracy: 0.6922\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 905us/step - loss: 0.5890 - accuracy: 0.7085\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5798 - accuracy: 0.7003\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5762 - accuracy: 0.7150\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5888 - accuracy: 0.7182\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 804us/step - loss: 0.5741 - accuracy: 0.7134\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5703 - accuracy: 0.7068\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5807 - accuracy: 0.7036\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5769 - accuracy: 0.7150\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5734 - accuracy: 0.7280\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 901us/step - loss: 0.5756 - accuracy: 0.7215\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.7052\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 924us/step - loss: 0.5555 - accuracy: 0.7345\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 883us/step - loss: 0.5769 - accuracy: 0.7182\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 859us/step - loss: 0.5633 - accuracy: 0.7231\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 770us/step - loss: 0.5662 - accuracy: 0.7134\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5540 - accuracy: 0.7394\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5610 - accuracy: 0.7378\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5750 - accuracy: 0.7117\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5664 - accuracy: 0.7231\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5525 - accuracy: 0.7280\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.5557 - accuracy: 0.7329\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7182\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7296\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5697 - accuracy: 0.7280\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5652 - accuracy: 0.7264\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 891us/step - loss: 0.5481 - accuracy: 0.7264\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5512 - accuracy: 0.7362\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 891us/step - loss: 0.5547 - accuracy: 0.7345\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 981us/step - loss: 0.5602 - accuracy: 0.7362\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5551 - accuracy: 0.7345\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5528 - accuracy: 0.7476\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5507 - accuracy: 0.7378\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5421 - accuracy: 0.7427\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5472 - accuracy: 0.7345\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5456 - accuracy: 0.7410\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7459\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 957us/step - loss: 0.5431 - accuracy: 0.7443\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 769us/step - loss: 0.5389 - accuracy: 0.7476\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 764us/step - loss: 0.5443 - accuracy: 0.7313\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5336 - accuracy: 0.7476\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 756us/step - loss: 0.5439 - accuracy: 0.7296\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5413 - accuracy: 0.7557\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5423 - accuracy: 0.7345\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5365 - accuracy: 0.7378\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5334 - accuracy: 0.7492\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5315 - accuracy: 0.7590\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.7378\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 876us/step - loss: 0.5326 - accuracy: 0.7345\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5394 - accuracy: 0.7410\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 799us/step - loss: 0.5532 - accuracy: 0.7459\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5355 - accuracy: 0.7476\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 823us/step - loss: 0.5340 - accuracy: 0.7459\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 829us/step - loss: 0.5296 - accuracy: 0.7508\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 924us/step - loss: 0.5470 - accuracy: 0.7362\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5299 - accuracy: 0.7541\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 892us/step - loss: 0.5280 - accuracy: 0.7492\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5345 - accuracy: 0.7524\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5318 - accuracy: 0.7476\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 809us/step - loss: 0.5266 - accuracy: 0.7410\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5397 - accuracy: 0.7329\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 859us/step - loss: 0.5524 - accuracy: 0.7166\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 883us/step - loss: 0.5292 - accuracy: 0.7427\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5248 - accuracy: 0.7476\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5288 - accuracy: 0.7459\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5352 - accuracy: 0.7524\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 850us/step - loss: 0.5233 - accuracy: 0.7476\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5305 - accuracy: 0.7410\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 883us/step - loss: 0.5241 - accuracy: 0.7427\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 891us/step - loss: 0.5206 - accuracy: 0.7459\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5187 - accuracy: 0.7557\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5297 - accuracy: 0.7476\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5196 - accuracy: 0.7541\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5222 - accuracy: 0.7508\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5284 - accuracy: 0.7410\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 883us/step - loss: 0.5330 - accuracy: 0.7362\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 908us/step - loss: 0.5232 - accuracy: 0.7427\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5250 - accuracy: 0.7524\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5247 - accuracy: 0.7459\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5184 - accuracy: 0.7492\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 867us/step - loss: 0.5256 - accuracy: 0.7508\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 859us/step - loss: 0.5382 - accuracy: 0.7606\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 866us/step - loss: 0.5191 - accuracy: 0.7427\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7508\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7362\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5112 - accuracy: 0.7671\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5161 - accuracy: 0.7524\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7557\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7443\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 883us/step - loss: 0.5267 - accuracy: 0.7459\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5311 - accuracy: 0.7394\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5057 - accuracy: 0.7606\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 829us/step - loss: 0.5164 - accuracy: 0.7459\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5143 - accuracy: 0.7378\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 773us/step - loss: 0.5093 - accuracy: 0.7557\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 795us/step - loss: 0.5178 - accuracy: 0.7443\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5088 - accuracy: 0.7687\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5112 - accuracy: 0.7524\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5069 - accuracy: 0.7622\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5245 - accuracy: 0.7541\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5144 - accuracy: 0.7362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2121f4cf190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(X_train,y_train,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b70de96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 892us/step - loss: 0.5023 - accuracy: 0.7687\n",
      "Train Accuracy 76.87296271324158\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "_,accuracy = kerasmodel.evaluate(X_train,y_train)\n",
    "print('Train Accuracy',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c9e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c0191e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.6411 - accuracy: 0.6710\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5696 - accuracy: 0.7101\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5785 - accuracy: 0.7068\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5754 - accuracy: 0.6954\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5991 - accuracy: 0.6971\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5756 - accuracy: 0.6954\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5377 - accuracy: 0.7345\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5822 - accuracy: 0.6873\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7003\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.5703 - accuracy: 0.7134\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.5511 - accuracy: 0.6987\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5874 - accuracy: 0.7101\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5463 - accuracy: 0.7068\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5449 - accuracy: 0.7166\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5323 - accuracy: 0.7150\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.7003\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 997us/step - loss: 0.5465 - accuracy: 0.7150\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5446 - accuracy: 0.7166\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7231\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.5377 - accuracy: 0.7117\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 973us/step - loss: 0.5369 - accuracy: 0.7215\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5209 - accuracy: 0.7215\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5351 - accuracy: 0.7215\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5305 - accuracy: 0.7248\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 908us/step - loss: 0.5346 - accuracy: 0.7345\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5277 - accuracy: 0.7362\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 867us/step - loss: 0.5370 - accuracy: 0.7231\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.5271 - accuracy: 0.7378\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5169 - accuracy: 0.7378\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5280 - accuracy: 0.7410\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5463 - accuracy: 0.7182\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 826us/step - loss: 0.5276 - accuracy: 0.7362\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5347 - accuracy: 0.7264\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 924us/step - loss: 0.5313 - accuracy: 0.7427\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5371 - accuracy: 0.7199\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5313 - accuracy: 0.7362\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.5274 - accuracy: 0.7378\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5207 - accuracy: 0.7476\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5187 - accuracy: 0.7443\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5242 - accuracy: 0.7215\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5297 - accuracy: 0.7313\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.5291 - accuracy: 0.7231\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5218 - accuracy: 0.7345\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5181 - accuracy: 0.7427\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 810us/step - loss: 0.5208 - accuracy: 0.7296\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5251 - accuracy: 0.7394\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 778us/step - loss: 0.5162 - accuracy: 0.7427\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5338 - accuracy: 0.7248\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 793us/step - loss: 0.5102 - accuracy: 0.7590\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5256 - accuracy: 0.7264\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 887us/step - loss: 0.5198 - accuracy: 0.7427\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 948us/step - loss: 0.5275 - accuracy: 0.7150\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7378\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 886us/step - loss: 0.5201 - accuracy: 0.7524\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 807us/step - loss: 0.5222 - accuracy: 0.7166\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 770us/step - loss: 0.5123 - accuracy: 0.7427\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 804us/step - loss: 0.5105 - accuracy: 0.7622\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 792us/step - loss: 0.5203 - accuracy: 0.7476\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5167 - accuracy: 0.7378\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 759us/step - loss: 0.5318 - accuracy: 0.7378\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5226 - accuracy: 0.7410\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 772us/step - loss: 0.5121 - accuracy: 0.7492\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5247 - accuracy: 0.7410\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7378\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7492\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.5031 - accuracy: 0.7427\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 821us/step - loss: 0.5067 - accuracy: 0.7687\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5042 - accuracy: 0.7443\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 754us/step - loss: 0.5070 - accuracy: 0.7606\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5225 - accuracy: 0.7345\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 753us/step - loss: 0.5211 - accuracy: 0.7345\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.4973 - accuracy: 0.7606\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.5204 - accuracy: 0.7476\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5272 - accuracy: 0.7280\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.4993 - accuracy: 0.7573\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5190 - accuracy: 0.7345\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 774us/step - loss: 0.4976 - accuracy: 0.7443\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5057 - accuracy: 0.7394\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5121 - accuracy: 0.7459\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5092 - accuracy: 0.7524\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 973us/step - loss: 0.4989 - accuracy: 0.7606\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.5140 - accuracy: 0.7410\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.5018 - accuracy: 0.7492\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 799us/step - loss: 0.5050 - accuracy: 0.7313\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5050 - accuracy: 0.7410\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5098 - accuracy: 0.7394\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5026 - accuracy: 0.7378\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.4990 - accuracy: 0.7508\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5161 - accuracy: 0.7541\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 817us/step - loss: 0.5015 - accuracy: 0.7362\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5086 - accuracy: 0.7394\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.5091 - accuracy: 0.7329\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.5042 - accuracy: 0.7524\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 769us/step - loss: 0.5012 - accuracy: 0.7524\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5093 - accuracy: 0.7378\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.4937 - accuracy: 0.7492\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.5174 - accuracy: 0.7443\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5038 - accuracy: 0.7687\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.5204 - accuracy: 0.7313\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5058 - accuracy: 0.7492\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.4986 - accuracy: 0.7687\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.4986 - accuracy: 0.7508\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.5211 - accuracy: 0.7296\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.4981 - accuracy: 0.7606\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.5013 - accuracy: 0.7443\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5098 - accuracy: 0.7557\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5113 - accuracy: 0.7508\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.4952 - accuracy: 0.7508\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.4967 - accuracy: 0.7606\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 764us/step - loss: 0.4996 - accuracy: 0.7573\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5194 - accuracy: 0.7296\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5027 - accuracy: 0.7508\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 875us/step - loss: 0.4891 - accuracy: 0.7655\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5043 - accuracy: 0.7378\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.5085 - accuracy: 0.7508\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 758us/step - loss: 0.5040 - accuracy: 0.7492\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5047 - accuracy: 0.7427\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.4965 - accuracy: 0.7443\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4938 - accuracy: 0.7720\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 737us/step - loss: 0.5254 - accuracy: 0.7362\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5125 - accuracy: 0.7394\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 786us/step - loss: 0.5128 - accuracy: 0.7329\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5056 - accuracy: 0.7345\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.4906 - accuracy: 0.7476\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.4993 - accuracy: 0.7638\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5034 - accuracy: 0.7557\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 759us/step - loss: 0.5042 - accuracy: 0.7655\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 776us/step - loss: 0.5071 - accuracy: 0.7541\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.4999 - accuracy: 0.7410\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 737us/step - loss: 0.4979 - accuracy: 0.7557\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 818us/step - loss: 0.5058 - accuracy: 0.7492\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.5042 - accuracy: 0.7508\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4977 - accuracy: 0.7590\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.4980 - accuracy: 0.7476\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5159 - accuracy: 0.7378\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.5012 - accuracy: 0.7345\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 779us/step - loss: 0.4988 - accuracy: 0.7590\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 989us/step - loss: 0.5095 - accuracy: 0.7378\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.4857 - accuracy: 0.7638\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 785us/step - loss: 0.4958 - accuracy: 0.7459\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.5049 - accuracy: 0.7459\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.4994 - accuracy: 0.7524\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 759us/step - loss: 0.5001 - accuracy: 0.7443\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5016 - accuracy: 0.7590\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 736us/step - loss: 0.5011 - accuracy: 0.7508\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 804us/step - loss: 0.5002 - accuracy: 0.7541\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.4940 - accuracy: 0.7524\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.5033 - accuracy: 0.7541\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.5018 - accuracy: 0.7524\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 728us/step - loss: 0.4971 - accuracy: 0.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21221b6abc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(X_train,y_train,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf6b14e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 810us/step - loss: 0.4887 - accuracy: 0.7752\n",
      "0.7752442955970764\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=kerasmodel.evaluate(X_train,y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f427effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b7fd5",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401b7f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Survived\n",
       "0       3    0  22.0      1      0   7.2500         1         0\n",
       "1       1    1  38.0      1      0  71.2833         0         1\n",
       "2       3    1  26.0      0      0   7.9250         1         1\n",
       "3       1    1  35.0      1      0  53.1000         1         1\n",
       "4       3    0  35.0      0      0   8.0500         1         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('titanics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b28859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1309 non-null   int64  \n",
      " 1   Sex       1309 non-null   int64  \n",
      " 2   Age       1223 non-null   float64\n",
      " 3   SibSp     1309 non-null   int64  \n",
      " 4   Parch     1309 non-null   int64  \n",
      " 5   Fare      1308 non-null   float64\n",
      " 6   Embarked  1309 non-null   int64  \n",
      " 7   Survived  1309 non-null   int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 81.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2682c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='Age',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9844666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1223 entries, 0 to 1306\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1223 non-null   int64  \n",
      " 1   Sex       1223 non-null   int64  \n",
      " 2   Age       1223 non-null   float64\n",
      " 3   SibSp     1223 non-null   int64  \n",
      " 4   Parch     1223 non-null   int64  \n",
      " 5   Fare      1222 non-null   float64\n",
      " 6   Embarked  1223 non-null   int64  \n",
      " 7   Survived  1223 non-null   int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 86.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8fcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare']=df['Fare'].fillna(df['Fare'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88332a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1223 entries, 0 to 1306\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1223 non-null   int64  \n",
      " 1   Sex       1223 non-null   int64  \n",
      " 2   Age       1223 non-null   float64\n",
      " 3   SibSp     1223 non-null   int64  \n",
      " 4   Parch     1223 non-null   int64  \n",
      " 5   Fare      1223 non-null   float64\n",
      " 6   Embarked  1223 non-null   int64  \n",
      " 7   Survived  1223 non-null   int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 86.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a003d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Survived',axis=1)\n",
    "y=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9fc8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a411aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras=Sequential()\n",
    "keras.add(Dense(64,input_dim=7,activation='relu'))\n",
    "keras.add(Dense(32,activation='relu'))\n",
    "keras.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9707e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef14f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "92/92 [==============================] - 1s 2ms/step - loss: 0.7393 - accuracy: 0.6347\n",
      "Epoch 2/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6947\n",
      "Epoch 3/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7143\n",
      "Epoch 4/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.7514\n",
      "Epoch 5/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.7503\n",
      "Epoch 6/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7688\n",
      "Epoch 7/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8092\n",
      "Epoch 8/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7786\n",
      "Epoch 9/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8332\n",
      "Epoch 10/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8342\n",
      "Epoch 11/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8321\n",
      "Epoch 12/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8244\n",
      "Epoch 13/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8321\n",
      "Epoch 14/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8484\n",
      "Epoch 15/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8386\n",
      "Epoch 16/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8473\n",
      "Epoch 17/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8375\n",
      "Epoch 18/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8495\n",
      "Epoch 19/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8364\n",
      "Epoch 20/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8441\n",
      "Epoch 21/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8451\n",
      "Epoch 22/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8430\n",
      "Epoch 23/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8451\n",
      "Epoch 24/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8386\n",
      "Epoch 25/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8353\n",
      "Epoch 26/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8495\n",
      "Epoch 27/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8408\n",
      "Epoch 28/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8419\n",
      "Epoch 29/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8430\n",
      "Epoch 30/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8506\n",
      "Epoch 32/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8506\n",
      "Epoch 33/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8528\n",
      "Epoch 34/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8430\n",
      "Epoch 35/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8517\n",
      "Epoch 36/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8517\n",
      "Epoch 37/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8419\n",
      "Epoch 38/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8430\n",
      "Epoch 39/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8506\n",
      "Epoch 40/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8604\n",
      "Epoch 41/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8419\n",
      "Epoch 42/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8561\n",
      "Epoch 43/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8539\n",
      "Epoch 44/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8528\n",
      "Epoch 45/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8561\n",
      "Epoch 46/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8451\n",
      "Epoch 47/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8615\n",
      "Epoch 48/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8561\n",
      "Epoch 49/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8593\n",
      "Epoch 50/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8571\n",
      "Epoch 51/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8539\n",
      "Epoch 52/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8593\n",
      "Epoch 53/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8441\n",
      "Epoch 54/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8561\n",
      "Epoch 55/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8648\n",
      "Epoch 56/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8593\n",
      "Epoch 57/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8615\n",
      "Epoch 58/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8539\n",
      "Epoch 59/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8550\n",
      "Epoch 60/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8571\n",
      "Epoch 61/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8637\n",
      "Epoch 62/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8626\n",
      "Epoch 63/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8561\n",
      "Epoch 64/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8648\n",
      "Epoch 65/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8691\n",
      "Epoch 66/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8539\n",
      "Epoch 67/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8615\n",
      "Epoch 68/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8626\n",
      "Epoch 69/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8637\n",
      "Epoch 70/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8626\n",
      "Epoch 71/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8550\n",
      "Epoch 72/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8582\n",
      "Epoch 73/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8637\n",
      "Epoch 74/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8615\n",
      "Epoch 75/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8539\n",
      "Epoch 76/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8582\n",
      "Epoch 77/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8582\n",
      "Epoch 78/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8648\n",
      "Epoch 79/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8637\n",
      "Epoch 80/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8604\n",
      "Epoch 81/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8626\n",
      "Epoch 82/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8604\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8604\n",
      "Epoch 84/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8571\n",
      "Epoch 85/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8626\n",
      "Epoch 86/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8702\n",
      "Epoch 87/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8604\n",
      "Epoch 88/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8615\n",
      "Epoch 89/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8626\n",
      "Epoch 90/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8604\n",
      "Epoch 91/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8713\n",
      "Epoch 92/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8691\n",
      "Epoch 93/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8746\n",
      "Epoch 94/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8615\n",
      "Epoch 95/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8713\n",
      "Epoch 96/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8659\n",
      "Epoch 97/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8648\n",
      "Epoch 98/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8691\n",
      "Epoch 99/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8670\n",
      "Epoch 100/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8713\n",
      "Epoch 101/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8724\n",
      "Epoch 102/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8746\n",
      "Epoch 103/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8691\n",
      "Epoch 104/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8626\n",
      "Epoch 105/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8648\n",
      "Epoch 106/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8724\n",
      "Epoch 107/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8637\n",
      "Epoch 108/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8648\n",
      "Epoch 109/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8648\n",
      "Epoch 110/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8648\n",
      "Epoch 111/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8735\n",
      "Epoch 112/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8659\n",
      "Epoch 113/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8691\n",
      "Epoch 114/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8735\n",
      "Epoch 115/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8713\n",
      "Epoch 116/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8680\n",
      "Epoch 117/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8757\n",
      "Epoch 118/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8735\n",
      "Epoch 119/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8691\n",
      "Epoch 120/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8757\n",
      "Epoch 121/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8724\n",
      "Epoch 122/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8735\n",
      "Epoch 123/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8702\n",
      "Epoch 124/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8735\n",
      "Epoch 125/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8648\n",
      "Epoch 126/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8680\n",
      "Epoch 127/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8724\n",
      "Epoch 128/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8724\n",
      "Epoch 129/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8713\n",
      "Epoch 130/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8724\n",
      "Epoch 131/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8637\n",
      "Epoch 132/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8713\n",
      "Epoch 133/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8735\n",
      "Epoch 134/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8648\n",
      "Epoch 135/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8691\n",
      "Epoch 136/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8724\n",
      "Epoch 137/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8735\n",
      "Epoch 138/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8724\n",
      "Epoch 139/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8746\n",
      "Epoch 140/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8735\n",
      "Epoch 141/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8768\n",
      "Epoch 142/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8779\n",
      "Epoch 143/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8724\n",
      "Epoch 144/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8800\n",
      "Epoch 145/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8790\n",
      "Epoch 146/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8713\n",
      "Epoch 147/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8768\n",
      "Epoch 148/150\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8768\n",
      "Epoch 149/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8800\n",
      "Epoch 150/150\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2762040a5f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.fit(X_train,y_train,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3884e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8800\n",
      "0.880043625831604\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = keras.evaluate(X_train,y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6244f",
   "metadata": {},
   "source": [
    "## Mobile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78cea2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep   \n",
       "0            842     0          2.2         0   1       0           7    0.6  \\\n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time   \n",
       "0        188        2  ...         20       756  2549     9     7         19  \\\n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1          1.0  \n",
       "1        1             1     0          2.0  \n",
       "2        1             1     0          2.0  \n",
       "3        1             0     0          2.0  \n",
       "4        1             1     0          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('mobile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97167caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  3000 non-null   int64  \n",
      " 1   blue           3000 non-null   int64  \n",
      " 2   clock_speed    3000 non-null   float64\n",
      " 3   dual_sim       3000 non-null   int64  \n",
      " 4   fc             3000 non-null   int64  \n",
      " 5   four_g         3000 non-null   int64  \n",
      " 6   int_memory     3000 non-null   int64  \n",
      " 7   m_dep          3000 non-null   float64\n",
      " 8   mobile_wt      3000 non-null   int64  \n",
      " 9   n_cores        3000 non-null   int64  \n",
      " 10  pc             3000 non-null   int64  \n",
      " 11  px_height      3000 non-null   int64  \n",
      " 12  px_width       3000 non-null   int64  \n",
      " 13  ram            3000 non-null   int64  \n",
      " 14  sc_h           3000 non-null   int64  \n",
      " 15  sc_w           3000 non-null   int64  \n",
      " 16  talk_time      3000 non-null   int64  \n",
      " 17  three_g        3000 non-null   int64  \n",
      " 18  touch_screen   3000 non-null   int64  \n",
      " 19  wifi           3000 non-null   int64  \n",
      " 20  price_range    2000 non-null   float64\n",
      "dtypes: float64(3), int64(18)\n",
      "memory usage: 492.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25d5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='price_range',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fa394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   float64\n",
      "dtypes: float64(3), int64(18)\n",
      "memory usage: 343.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db46510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('price_range',axis=1)\n",
    "y=df['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7011c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f04f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55550943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "keras=Sequential()\n",
    "keras.add(Dense(64,input_dim=20,activation='relu'))\n",
    "keras.add(Dense(32,activation='LeakyReLU'))\n",
    "keras.add(Dense(4,activation='relu'))\n",
    "keras.add(Dense(1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0254c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de0a2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 1ms/step - loss: -794394820608.0000 - accuracy: 0.2513\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -808987787264.0000 - accuracy: 0.2513\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -824080269312.0000 - accuracy: 0.2513\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -839631306752.0000 - accuracy: 0.2513\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -855441014784.0000 - accuracy: 0.2513\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -871660453888.0000 - accuracy: 0.2513\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -888202461184.0000 - accuracy: 0.2513\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -905091612672.0000 - accuracy: 0.2513\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -922344554496.0000 - accuracy: 0.2513\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -939882971136.0000 - accuracy: 0.2513\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -957757784064.0000 - accuracy: 0.2513\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -975970893824.0000 - accuracy: 0.2513\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -994373402624.0000 - accuracy: 0.2513\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1013238464512.0000 - accuracy: 0.2513\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1032420130816.0000 - accuracy: 0.2513\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1051948613632.0000 - accuracy: 0.2513\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1071809822720.0000 - accuracy: 0.2513\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1092041637888.0000 - accuracy: 0.2513\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1112583045120.0000 - accuracy: 0.2513\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1133471203328.0000 - accuracy: 0.2513\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1154724528128.0000 - accuracy: 0.2513\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1176354816000.0000 - accuracy: 0.2513\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1198283292672.0000 - accuracy: 0.2513\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1220619796480.0000 - accuracy: 0.2513\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1243278082048.0000 - accuracy: 0.2513\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1266238357504.0000 - accuracy: 0.2513\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1289580707840.0000 - accuracy: 0.2513\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1313168818176.0000 - accuracy: 0.2513\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1337139527680.0000 - accuracy: 0.2513\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1361469243392.0000 - accuracy: 0.2513\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1386064117760.0000 - accuracy: 0.2513\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1411166109696.0000 - accuracy: 0.2513\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1436572581888.0000 - accuracy: 0.2513\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1462342385664.0000 - accuracy: 0.2513\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1488610525184.0000 - accuracy: 0.2513\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1515114463232.0000 - accuracy: 0.2513\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1542083182592.0000 - accuracy: 0.2513\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1569393737728.0000 - accuracy: 0.2513\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1596985835520.0000 - accuracy: 0.2513\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1625108119552.0000 - accuracy: 0.2513\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1653565947904.0000 - accuracy: 0.2513\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1682193776640.0000 - accuracy: 0.2513\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1711406972928.0000 - accuracy: 0.2513\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1740946407424.0000 - accuracy: 0.2513\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1770935156736.0000 - accuracy: 0.2513\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1801323806720.0000 - accuracy: 0.2513\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1832052457472.0000 - accuracy: 0.2513\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1863220199424.0000 - accuracy: 0.2513\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1894828998656.0000 - accuracy: 0.2513\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1926635716608.0000 - accuracy: 0.2513\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 2ms/step - loss: -1958978256896.0000 - accuracy: 0.2513\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -1991504691200.0000 - accuracy: 0.2513\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2024685174784.0000 - accuracy: 0.2513\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 2ms/step - loss: -2058078126080.0000 - accuracy: 0.2513\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2091961548800.0000 - accuracy: 0.2513\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2126204633088.0000 - accuracy: 0.2513\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2160910925824.0000 - accuracy: 0.2513\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2195987103744.0000 - accuracy: 0.2513\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2231437885440.0000 - accuracy: 0.2513\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2267271135232.0000 - accuracy: 0.2513\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2303631032320.0000 - accuracy: 0.2513\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2340358193152.0000 - accuracy: 0.2513\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2377515794432.0000 - accuracy: 0.2513\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2415003697152.0000 - accuracy: 0.2513\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2453088501760.0000 - accuracy: 0.2513\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2491517239296.0000 - accuracy: 0.2513\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2530280734720.0000 - accuracy: 0.2513\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2569473359872.0000 - accuracy: 0.2513\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2609247420416.0000 - accuracy: 0.2513\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2649294110720.0000 - accuracy: 0.2513\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2689971781632.0000 - accuracy: 0.2513\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2731144118272.0000 - accuracy: 0.2513\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2772636270592.0000 - accuracy: 0.2513\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2814727684096.0000 - accuracy: 0.2513\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2857320841216.0000 - accuracy: 0.2513\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2900342079488.0000 - accuracy: 0.2513\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2944020512768.0000 - accuracy: 0.2513\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -2987870650368.0000 - accuracy: 0.2513\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3032400527360.0000 - accuracy: 0.2513\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3077168431104.0000 - accuracy: 0.2513\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3122732466176.0000 - accuracy: 0.2513\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3168415252480.0000 - accuracy: 0.2513\n",
      "Epoch 83/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3214738718720.0000 - accuracy: 0.2513\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3261655154688.0000 - accuracy: 0.2513\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3309025624064.0000 - accuracy: 0.2513\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3356737142784.0000 - accuracy: 0.2513\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3404862849024.0000 - accuracy: 0.2513\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3453576019968.0000 - accuracy: 0.2513\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3502601404416.0000 - accuracy: 0.2513\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3552434716672.0000 - accuracy: 0.2513\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3602556911616.0000 - accuracy: 0.2513\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3653310349312.0000 - accuracy: 0.2513\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3704672485376.0000 - accuracy: 0.2513\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3756614221824.0000 - accuracy: 0.2513\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3809044594688.0000 - accuracy: 0.2513\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3861922971648.0000 - accuracy: 0.2513\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3915293917184.0000 - accuracy: 0.2513\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -3969264123904.0000 - accuracy: 0.2513\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4023724277760.0000 - accuracy: 0.2513\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4079001010176.0000 - accuracy: 0.2513\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4134727319552.0000 - accuracy: 0.2513\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4191035064320.0000 - accuracy: 0.2513\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4247742316544.0000 - accuracy: 0.2513\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4305015799808.0000 - accuracy: 0.2513\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4362852368384.0000 - accuracy: 0.2513\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4421245730816.0000 - accuracy: 0.2513\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4480057737216.0000 - accuracy: 0.2513\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4539634155520.0000 - accuracy: 0.2513\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4599637344256.0000 - accuracy: 0.2513\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4660360380416.0000 - accuracy: 0.2513\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4721453039616.0000 - accuracy: 0.2513\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4783202107392.0000 - accuracy: 0.2513\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4845373751296.0000 - accuracy: 0.2513\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4908333924352.0000 - accuracy: 0.2513\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -4971359633408.0000 - accuracy: 0.2513\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5035366809600.0000 - accuracy: 0.2513\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5100059754496.0000 - accuracy: 0.2513\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5165242384384.0000 - accuracy: 0.2513\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5231270166528.0000 - accuracy: 0.2513\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5297702699008.0000 - accuracy: 0.2513\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5364987723776.0000 - accuracy: 0.2513\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5432740413440.0000 - accuracy: 0.2513\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5500995371008.0000 - accuracy: 0.2513\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5570120122368.0000 - accuracy: 0.2513\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5639417364480.0000 - accuracy: 0.2513\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5709565001728.0000 - accuracy: 0.2513\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5780229586944.0000 - accuracy: 0.2513\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5851509686272.0000 - accuracy: 0.2513\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5923219701760.0000 - accuracy: 0.2513\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -5995764908032.0000 - accuracy: 0.2513\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6068815527936.0000 - accuracy: 0.2513\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6142569218048.0000 - accuracy: 0.2513\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6217132408832.0000 - accuracy: 0.2513\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6292346241024.0000 - accuracy: 0.2513\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6368138887168.0000 - accuracy: 0.2513\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6444861620224.0000 - accuracy: 0.2513\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6522067222528.0000 - accuracy: 0.2513\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6600030945280.0000 - accuracy: 0.2513\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6678749118464.0000 - accuracy: 0.2513\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6758266306560.0000 - accuracy: 0.2513\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6838598762496.0000 - accuracy: 0.2513\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -6919627472896.0000 - accuracy: 0.2513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7000843878400.0000 - accuracy: 0.2513\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7083099947008.0000 - accuracy: 0.2513\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7165681074176.0000 - accuracy: 0.2513\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7249214832640.0000 - accuracy: 0.2513\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7333068406784.0000 - accuracy: 0.2513\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7417367101440.0000 - accuracy: 0.2513\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7502791966720.0000 - accuracy: 0.2513\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: -7588296523776.0000 - accuracy: 0.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2762acef430>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.fit(X_train,y_train,epochs=150,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7873700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: -7632715251712.0000 - accuracy: 0.2513\n",
      "0.2513333261013031\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=keras.evaluate(X_train,y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26fcd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.68334261, 0.19982015, 0.35718513, 0.87953982, 0.2061754 ],\n",
       "        [0.17927507, 0.91540991, 0.64349541, 0.49610859, 0.16033204]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b2694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
